{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon, LineString\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkConf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config('spark.executor.cores', '8').config('spark.executor.memory', '80g')\\\n",
    "        .config(\"spark.sql.session.timeZone\", \"UTC\").config('spark.driver.memory', '80g').master(\"local[26]\")\\\n",
    "        .appName(\"wego-daily\").config('spark.driver.extraJavaOptions', '-Duser.timezone=UTC').config('spark.executor.extraJavaOptions', '-Duser.timezone=UTC')\\\n",
    "        .config(\"spark.sql.datetime.java8API.enabled\", \"true\").config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "        .config(\"spark.sql.autoBroadcastJoinThreshold\", -1)\\\n",
    "        .config(\"spark.driver.maxResultSize\", 0)\\\n",
    "        .config(\"spark.shuffle.spill\", \"true\")\\\n",
    "        .config(\"spark.driver.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true\")\\\n",
    "        .config(\"spark.executor.extraJavaOptions\", \"-Dio.netty.tryReflectionSetAccessible=true\")\\\n",
    "        .config(\"spark.ui.showConsoleProgress\", \"false\")\\\n",
    "        .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'shapefiles', \"tncounty\")\n",
    "gdf_county = gpd.read_file(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_county.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_dav = gdf_county[gdf_county[\"NAME\"] == \"Davidson\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_david = gdf_dav.to_crs(\"EPSG:4326\")\n",
    "gdf_david.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = gdf_dav.total_bounds\n",
    "gdf_dav.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 5280\n",
    "wide = 5280\n",
    "\n",
    "cols = list(np.arange(xmin, xmax + wide, wide))\n",
    "print(len(cols))\n",
    "rows = list(np.arange(ymin, ymax + length, length))\n",
    "print(len(cols))\n",
    "\n",
    "polygons = []\n",
    "for x in cols[:-1]:\n",
    "    for y in rows[:-1]:\n",
    "        polygons.append(Polygon([(x,y), (x+wide, y), (x+wide, y+length), (x, y+length)]))\n",
    "\n",
    "grid = gpd.GeoDataFrame({'geometry':polygons})\n",
    "fp = os.path.join('data', 'shapefiles', 'grid_shapes.shp')\n",
    "grid.to_file(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.plot(ax = gdf_dav.plot(color='blue'), color='none', edgecolor='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = grid.set_crs(\"EPSG:2274\")\n",
    "grids.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dav_grids = gpd.overlay(gdf_dav, grids, how='intersection')\n",
    "dav_grids.plot(figsize=(10, 10))\n",
    "plt.show()\n",
    "dav_grids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dav_grids['row_num'] = np.arange(len(dav_grids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dav_grids2 = dav_grids.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dav_grids2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = os.path.join('data', '1x1grids_davidson.pkl')\n",
    "# dav_grids2.to_pickle(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rtree would be faster\n",
    "def find_grids_intersecting(gdf, linestring):\n",
    "    spatial_index = gdf.sindex\n",
    "    possible_matches_index = list(spatial_index.intersection(linestring.bounds))\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    precise_matches = possible_matches[possible_matches.intersects(linestring)]\n",
    "    return precise_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get route linestring data\n",
    "fp = os.path.join('data', 'route_geoms_df.pkl')\n",
    "trip_id_geom_data = pd.read_pickle(fp)\n",
    "trip_id_geom_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "ax = dav_grids2.plot(facecolor='none', figsize=(10, 10))\n",
    "\n",
    "ls2 = trip_id_geom_data.sample(1).iloc[0].geometry\n",
    "gdf = find_grids_intersecting(dav_grids2, ls2)\n",
    "gdf.plot(ax=ax, facecolor='red', alpha=0.6)\n",
    "ax.plot(*ls2.coords.xy, c='blue', label='Bus route')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_segments_in_grids(grids, inrix_data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mile = 1609.34 # meters\n",
    "meter2 = dav_grids.iloc[0].geometry.area\n",
    "mile2 = meter2/(mile * mile)\n",
    "mile2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe of trips and linestring geometries\n",
    "* Probably a simpler way but the GTFS one doesnt seem complete (i dont have all GTFS files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.path.join('..', '..', 'data', 'processed_parquet_JP_all')\n",
    "apcdata = spark.read.load(f)\n",
    "apcdata = apcdata.sort(\"arrival_time\")\\\n",
    "            .select(\"transit_date\", \"trip_id\", \"map_longitude\", \"map_latitude\")\\\n",
    "            .groupby('transit_date', 'trip_id')\\\n",
    "            .agg(F.collect_list(\"map_longitude\").alias(\"map_longitude\"), F.collect_list(\"map_latitude\").alias(\"map_latitude\"))\n",
    "\n",
    "apcdata = apcdata.drop(\"transit_date\")\n",
    "apcdata = apcdata.dropDuplicates(['trip_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lineString(x):\n",
    "    geometry = [xy for xy in zip(x.map_longitude, x.map_latitude)]\n",
    "    return LineString(geometry)\n",
    "\n",
    "apcdf = apcdata.toPandas()\n",
    "apcdf['geometry'] = apcdf.apply(lambda x: create_lineString(x), axis=1)\n",
    "apcdf = apcdf.set_geometry('geometry')\n",
    "apcdf = apcdf.drop(columns=['map_longitude', 'map_latitude'], axis=1)\n",
    "# fp = os.path.join('data', 'route_geoms_df.pkl')\n",
    "# apcdf.to_pickle(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "* Loop through all trips\n",
    "    * Get corresponding route `LineString` per trip\n",
    "    * Find which `dav_grids2` the LS intersects\n",
    "    * Find which segments are in the grids\n",
    "    * Get congestion data for the date time window of that trip\n",
    "    * Get the average across all segments\n",
    "    * Assign as new column to trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get processed trip level trip data\n",
    "fp = os.path.join('data', 'triplevel_df_processed_time_window_with_IDs.pickle')\n",
    "trip_df = pd.read_pickle(fp)\n",
    "trip_df = trip_df.dropna()\n",
    "trip_df = trip_df.sort_values(by=['transit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193685</td>\n",
       "      <td>LINESTRING (-86.78192 36.16709, -86.77742 36.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_id                                           geometry\n",
       "0  193685  LINESTRING (-86.78192 36.16709, -86.77742 36.1..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get route linestring data\n",
    "fp = os.path.join('data', 'route_geoms_df.pkl')\n",
    "trip_id_geom_data = pd.read_pickle(fp)\n",
    "trip_id_geom_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate/load 1x1 mile grids\n",
    "fp = os.path.join('data', '1x1grids_davidson.pkl')\n",
    "grids_df = pd.read_pickle(fp)\n",
    "grids_df = grids_df.set_geometry('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inrix segment data\n",
    "fp = os.path.join('data', 'inrix_grouped.pkl')\n",
    "with open(fp, \"rb\") as fh:\n",
    "  inrix_segment_df = pickle.load(fh)\n",
    "\n",
    "inrix_segment_df = inrix_segment_df.set_geometry('geometry')\n",
    "inrix_segment_df = inrix_segment_df[inrix_segment_df['County_inrix'] == 'davidson']\n",
    "davidson_segs = inrix_segment_df.XDSegID.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def find_grids_intersecting(gdf, linestring):\n",
    "    spatial_index = gdf.sindex\n",
    "    possible_matches_index = list(spatial_index.intersection(linestring.bounds))\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    precise_matches = possible_matches[possible_matches.intersects(linestring)]\n",
    "    return precise_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting segments in trips\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "# Get APC data\n",
    "fp = os.path.join('data', 'triplevel_df_processed_MAIN_NOTEBOOK.pickle')\n",
    "df = pd.read_pickle(fp)\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates(subset=['trip_id', 'route_id_direction'], keep='first')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "CORES = cpu_count()\n",
    "\n",
    "def merge_cluster(idx):\n",
    "    trip_ids = df.iloc[idx].trip_id.tolist()\n",
    "    all_used_segments = []\n",
    "    for trip_id in trip_ids:\n",
    "        route_linestring = trip_id_geom_data[trip_id_geom_data['trip_id'] == trip_id]['geometry'].values[0]\n",
    "        if route_linestring is None: \n",
    "            print(\"trip id LS not found.\")\n",
    "        \n",
    "        route_grids = find_grids_intersecting(grids_df, route_linestring)\n",
    "        if route_grids.empty: \n",
    "            print(\"route grids for trip not found.\")\n",
    "        \n",
    "        route_segments = inrix_segment_df[inrix_segment_df['geometry'].within(route_grids.unary_union)]['XDSegID'].tolist()\n",
    "        if len(route_segments) == 0: \n",
    "            print(\"route segments for trip not found.\")\n",
    "        \n",
    "        all_used_segments = list(set(all_used_segments + route_segments))\n",
    "    return all_used_segments\n",
    "o_index_group = np.array_split(df.index, CORES)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=CORES) as pool:\n",
    "    results = pool.map(merge_cluster, o_index_group)\n",
    "results = list(results)\n",
    "out = []\n",
    "[out.extend(r) for r in results]\n",
    "results = list(set(out))\n",
    "fp = os.path.join('data', 'XDSegIDs_for_all_trips.pkl')\n",
    "with open(fp, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting speed estimates per trip\n",
    "* `python_files/assign_speeds_to_trips.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
