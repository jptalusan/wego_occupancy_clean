{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0938411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/media/seconddrive/mta_stationing_problem\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e19e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime as dt\n",
    "import importlib\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row, SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkConf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, concatenate, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "import IPython\n",
    "from copy import deepcopy\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "from src import tf_utils, config, data_utils, models, linklevel_utils\n",
    "\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import swifter\n",
    "pd.set_option('display.max_columns', None)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c37ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.models' from '/media/seconddrive/mta_stationing_problem/src/models.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(tf_utils)\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa82f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedcd47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/06 00:53:43 WARN Utils: Your hostname, scope-vanderbilt resolves to a loopback address: 127.0.1.1; using 10.2.218.69 instead (on interface enp8s0)\n",
      "22/08/06 00:53:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/06 00:53:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/06 00:53:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/08/06 00:53:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/08/06 00:53:44 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config('spark.executor.cores', '8').config('spark.executor.memory', '80g')\\\n",
    "        .config(\"spark.sql.session.timeZone\", \"UTC\").config('spark.driver.memory', '40g').master(\"local[26]\")\\\n",
    "        .appName(\"wego-daily\").config('spark.driver.extraJavaOptions', '-Duser.timezone=UTC').config('spark.executor.extraJavaOptions', '-Duser.timezone=UTC')\\\n",
    "        .config(\"spark.sql.datetime.java8API.enabled\", \"true\").config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "        .config(\"spark.sql.autoBroadcastJoinThreshold\", -1)\\\n",
    "        .config(\"spark.driver.maxResultSize\", 0)\\\n",
    "        .config(\"spark.shuffle.spill\", \"true\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17026171",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.path.join('data', 'processed', 'apc_weather_gtfs.parquet')\n",
    "apcdata = spark.read.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eedb22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "todelete = apcdata.filter('(load < 0) OR (load IS NULL)').select('transit_date','trip_id','overload_id').distinct()\n",
    "todelete=todelete.withColumn('marker',F.lit(1))\n",
    "\n",
    "#joining and whereever the records are not found in sync error table the marker will be null\n",
    "apcdataafternegdelete=apcdata.join(todelete,on=['trip_id','transit_date','overload_id'],how='left').filter('marker is null').drop('marker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcc09244",
   "metadata": {},
   "outputs": [],
   "source": [
    "apcdataafternegdelete = apcdataafternegdelete.sort(['trip_id', 'overload_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/06 00:53:49 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " trip_id                                | 193637                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " transit_date                           | 2020-02-21 00:00:00                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " overload_id                            | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      " gtfs_date                              | 2020-01-24 00:00:00                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " dayofweek                              | 6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      " hour                                   | 23                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " gtfs_route_id                          | 14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " gtfs_direction_id                      | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      " stop_id                                | MEALYTNN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " day                                    | 21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " vehicle_id                             | 1919                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " block_abbr                             | 1403                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " activation_date                        | 2019-10-27 00:00:00                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " activation_date_str                    | 10/27/19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " arrival_time                           | 2020-02-21 23:38:48                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " arrival_time_str                       | 23:38:48                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " block_stop_order                       | 616                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " deactivation_date                      | 2020-03-11 00:00:00                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " deactivation_date_str                  | 03/11/20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " departure_time                         | 2020-02-21 23:39:02                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " departure_time_str                     | 23:39:02                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " load                                   | 11.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " load_factor                            | 0.275                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " map_latitude                           | 36.221755                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      " map_longitude                          | -86.825068                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      " offs                                   | 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " ons                                    | 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " pattern_num                            | -4922319677812129753                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " route_direction_name                   | FROM DOWNTOWN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      " route_id                               | 14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " scheduled_time                         | 2020-02-21 23:38:26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " scheduled_time_str                     | 23:38:26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " source_pattern_id                      | null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " stop_id_list                           | ['MCC', 'UNI2AEF', '1SWOONM', '1SJAMNM', '1SOLDNN', '1SOLDNM', 'N1SSPRNN', 'DICGRANN', 'DICHANNN', 'DICCLENN', 'DICWHISN', 'FERBRIWN', 'BAPVASWN', 'BAPWEANN', 'BAPLOCNM', 'BAPSEMNN', 'BAPHAYN', 'BAPMEANM', 'BAPYOUNN', 'WHITONWN', 'WHILUZNF', 'WHINOCWN', 'WHIAVANN', 'WHIFRANN', 'WHIMOONN', 'WHIREVNN', 'REVPAIWN', 'REVROWWN', 'ROWCARWN', 'ROWBONWN', 'ROWCROWN', 'ROWBUESN', 'WHAWALEF', 'HAMFLIWN', 'TUCDORNN', 'TUCHUMNN', 'TUCKINNN', 'KINMEAEN', 'MEALYTNN', 'LYTBOYNN', 'BOYFARNN', 'BOYAMENN', 'BOYBUENN'] \n",
      " stop_id_original                       | MEALYTNN                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " stop_name                              | MEADOW HILL DR & LYTLE DR NB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      " stop_sequence                          | 39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " stop_sequence_list                     | [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]                                                                                                                                                                                                                                                                                                                                                       \n",
      " transit_date_str                       | 02/21/20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " update_date                            | 2021-12-16 00:00:00                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " vehicle_capacity                       | 40.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " zero_load_at_trip_end                  | null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " count                                  | null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " darksky_temperature                    | 29.067                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " darksky_humidity                       | 0.66                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " darksky_nearest_storm_distance         | 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " darksky_precipitation_intensity        | 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " darksky_precipitation_probability      | 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " darksky_pressure                       | 1034.4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " darksky_wind_gust                      | 3.09                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " darksky_wind_speed                     | 1.8239999999999998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " weatherbit_rh                          | 57.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " weatherbit_wind_spd                    | 1.6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " weatherbit_app_temp                    | -3.9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " weatherbit_temp                        | -1.7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " weatherbit_snow                        | 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " weatherbit_precip                      | 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " gtfs_file                              | 24-Jan-2020.zip                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " gtfs_shape_id                          | 13955                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      " gtfs_start_date                        | 2020-01-24 00:00:00                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " gtfs_end_date                          | 2020-03-28 00:00:00                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " gtfs_number_of_scheduled_trips         | null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " gtfs_number_of_scheduled_trips_at_stop | null                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " delay_time                             | -22                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " dwell_time                             | 14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
      " prev_sched                             | 2020-02-21 22:40:26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " sched_hdwy                             | 3480                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " prev_depart                            | 2020-02-21 22:39:04                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " actual_hdwy                            | 3598                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " is_gapped                              | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      " is_bunched                             | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      " is_target                              | 1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      " year                                   | 2020                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      " month                                  | 2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apcdataafternegdelete.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5abc0370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT trip_id, transit_date, arrival_time, block_abbr, stop_sequence, stop_id_original, load, darksky_temperature, darksky_humidity, darksky_precipitation_probability, route_direction_name, route_id, dayofweek, year, month, hour, sched_hdwy\n",
      "FROM apc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_columns = ['trip_id', 'transit_date', 'arrival_time', \n",
    "               'block_abbr', 'stop_sequence', 'stop_id_original',\n",
    "               'load', \n",
    "               'darksky_temperature', \n",
    "               'darksky_humidity', \n",
    "               'darksky_precipitation_probability', \n",
    "               'route_direction_name', 'route_id',\n",
    "               'dayofweek',  'year', 'month', 'hour',\n",
    "               'sched_hdwy']\n",
    "get_str = \", \".join([c for c in get_columns])\n",
    "\n",
    "apcdataafternegdelete.createOrReplaceTempView(\"apc\")\n",
    "\n",
    "# # filter subset\n",
    "query = f\"\"\"\n",
    "SELECT {get_str}\n",
    "FROM apc\n",
    "\"\"\"\n",
    "print(query)\n",
    "\n",
    "apcdataafternegdelete = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edbbd659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16683167, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>transit_date</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>block_abbr</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_id_original</th>\n",
       "      <th>load</th>\n",
       "      <th>darksky_temperature</th>\n",
       "      <th>darksky_humidity</th>\n",
       "      <th>darksky_precipitation_probability</th>\n",
       "      <th>route_direction_name</th>\n",
       "      <th>route_id</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>sched_hdwy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193637</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2020-02-21 23:38:48</td>\n",
       "      <td>1403</td>\n",
       "      <td>39</td>\n",
       "      <td>MEALYTNN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.067</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FROM DOWNTOWN</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_id transit_date        arrival_time  block_abbr  stop_sequence  \\\n",
       "0  193637   2020-02-21 2020-02-21 23:38:48        1403             39   \n",
       "\n",
       "  stop_id_original  load  darksky_temperature  darksky_humidity  \\\n",
       "0         MEALYTNN  11.0               29.067              0.66   \n",
       "\n",
       "   darksky_precipitation_probability route_direction_name  route_id  \\\n",
       "0                                0.0        FROM DOWNTOWN        14   \n",
       "\n",
       "   dayofweek  year  month  hour  sched_hdwy  \n",
       "0          6  2020      2  23.0      3480.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = apcdataafternegdelete.toPandas()\n",
    "print(df.shape)\n",
    "old_shape = df.shape[0]\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.arrival_time.notna()]\n",
    "df = df[df.sched_hdwy.notna()]\n",
    "df = df[df.darksky_temperature.notna()]\n",
    "\n",
    "df['route_id_dir'] = df[\"route_id\"].astype(\"str\") + \"_\" + df[\"route_direction_name\"]\n",
    "df['day'] = df[\"arrival_time\"].dt.day\n",
    "df = df.sort_values(by=['block_abbr', 'arrival_time']).reset_index(drop=True)\n",
    "\n",
    "# Adding extra features\n",
    "# Holidays\n",
    "fp = os.path.join('data', 'others', 'US Holiday Dates (2004-2021).csv')\n",
    "holidays_df = pd.read_csv(fp)\n",
    "holidays_df['Date'] = pd.to_datetime(holidays_df['Date'])\n",
    "holidays_df['is_holiday'] = True\n",
    "df = df.merge(holidays_df[['Date', 'is_holiday']], left_on='transit_date', right_on='Date', how='left')\n",
    "df['is_holiday'] = df['is_holiday'].fillna(False)\n",
    "df = df.drop(columns=['Date'])\n",
    "\n",
    "# Traffic\n",
    "# Causes 3M data points to be lost\n",
    "fp = os.path.join('data', 'traffic', 'triplevel_speed.pickle')\n",
    "speed_df = pd.read_pickle(fp)\n",
    "speed_df = speed_df.rename({'route_id_direction':'route_id_dir'}, axis=1)\n",
    "speed_df = speed_df[['transit_date', 'trip_id', 'route_id_dir', 'traffic_speed']]\n",
    "df = df.merge(speed_df, how='left', \n",
    "                left_on=['transit_date', 'trip_id', 'route_id_dir'], \n",
    "                right_on=['transit_date', 'trip_id', 'route_id_dir'])\n",
    "# df = df[~df['traffic_speed'].isna()]\n",
    "df['traffic_speed'].bfill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2242087"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_shape - df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:07<00:00, 31.50it/s]\n"
     ]
    }
   ],
   "source": [
    "sorted_df = []\n",
    "for ba in tqdm(df.block_abbr.unique()):\n",
    "    ba_df = df[df['block_abbr'] == ba]\n",
    "    end_stop = ba_df.stop_sequence.max()\n",
    "    # Same result as creating a fixed_arrival_time (but faster)\n",
    "    ba_df = ba_df[ba_df.stop_sequence != end_stop].reset_index(drop=True)\n",
    "    sorted_df.append(ba_df)\n",
    "        \n",
    "overall_df = pd.concat(sorted_df)\n",
    "drop_cols = ['route_direction_name', 'route_id', 'trip_id']\n",
    "drop_cols = [col for col in drop_cols if col in overall_df.columns]\n",
    "overall_df = overall_df.drop(drop_cols, axis=1)\n",
    "\n",
    "# overall_df = overall_df.rename({\"fixed_arrival_time\": \"arrival_time\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEWINDOW = 15\n",
    "overall_df['minute'] = overall_df['arrival_time'].dt.minute\n",
    "overall_df['minuteByWindow'] = overall_df['minute'] // TIMEWINDOW\n",
    "overall_df['temp'] = overall_df['minuteByWindow'] + (overall_df['hour'] * 60 / TIMEWINDOW)\n",
    "overall_df['time_window'] = np.floor(overall_df['temp']).astype('int')\n",
    "overall_df = overall_df.drop(columns=['minute', 'minuteByWindow', 'temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate stops by time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14371083, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transit_date</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>block_abbr</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_id_original</th>\n",
       "      <th>load</th>\n",
       "      <th>darksky_temperature</th>\n",
       "      <th>darksky_humidity</th>\n",
       "      <th>darksky_precipitation_probability</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>sched_hdwy</th>\n",
       "      <th>route_id_dir</th>\n",
       "      <th>day</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>traffic_speed</th>\n",
       "      <th>time_window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-01 10:01:17</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>MCC5_5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>40.15</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18.639604</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transit_date        arrival_time  block_abbr  stop_sequence  \\\n",
       "0   2020-01-01 2020-01-01 10:01:17         300              1   \n",
       "\n",
       "  stop_id_original  load  darksky_temperature  darksky_humidity  \\\n",
       "0           MCC5_5   7.0                40.15             0.616   \n",
       "\n",
       "   darksky_precipitation_probability  dayofweek  year  month  hour  \\\n",
       "0                                0.0          4  2020      1  10.0   \n",
       "\n",
       "   sched_hdwy     route_id_dir  day  is_holiday  traffic_speed  time_window  \n",
       "0      4800.0  3_FROM DOWNTOWN    1        True      18.639604           40  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(overall_df.shape)\n",
    "overall_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by time windows and get the maximum of the aggregate load/class/sched\n",
    "# Get mean of temperature (mostly going to be equal)\n",
    "# TODO: Double check this! \n",
    "overall_df = overall_df.groupby(['transit_date', \n",
    "                                 'route_id_dir', \n",
    "                                 'stop_id_original',\n",
    "                                 'time_window']).agg({\"block_abbr\":\"first\",\n",
    "                                                      \"arrival_time\":\"first\",\n",
    "                                                      \"year\":\"first\", \n",
    "                                                      \"month\":\"first\",\n",
    "                                                      \"day\": \"first\",\n",
    "                                                      \"hour\":\"first\",\n",
    "                                                      \"is_holiday\": \"first\",\n",
    "                                                      \"dayofweek\":\"first\",\n",
    "                                                      \"stop_sequence\":\"first\",\n",
    "                                                      \"darksky_temperature\":\"mean\", \n",
    "                                                      \"darksky_humidity\":\"mean\",\n",
    "                                                      \"darksky_precipitation_probability\": \"mean\",\n",
    "                                                      \"traffic_speed\":\"mean\",\n",
    "                                                      \"sched_hdwy\": \"max\",\n",
    "                                                      \"load\": \"sum\" })\n",
    "overall_df = overall_df.reset_index(level=[0,1,2,3])\n",
    "overall_df = overall_df.sort_values(by=['block_abbr', 'arrival_time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13984203, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transit_date</th>\n",
       "      <th>route_id_dir</th>\n",
       "      <th>stop_id_original</th>\n",
       "      <th>time_window</th>\n",
       "      <th>block_abbr</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>darksky_temperature</th>\n",
       "      <th>darksky_humidity</th>\n",
       "      <th>darksky_precipitation_probability</th>\n",
       "      <th>traffic_speed</th>\n",
       "      <th>sched_hdwy</th>\n",
       "      <th>load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES18AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:46:14</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES19AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:46:26</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES20AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:46:58</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES21AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:47:12</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES23AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:48:24</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES24AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:48:28</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES25AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:48:50</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WESNATWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:49:18</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES27AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:49:30</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES29AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:49:42</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES30AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:50:08</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES31AWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:51:53</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WESACKWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:52:04</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WES440WN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:52:26</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WESELMWF</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:52:56</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WESBOWWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:53:40</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WESCRAWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:53:58</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WESWILWM</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:54:36</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WESMOCWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:54:42</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>WESLAUWN</td>\n",
       "      <td>63</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-01-01 15:54:50</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>52.555</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.727612</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    transit_date     route_id_dir stop_id_original  time_window  block_abbr  \\\n",
       "100   2020-01-01  3_FROM DOWNTOWN         WES18AWN           63         300   \n",
       "101   2020-01-01  3_FROM DOWNTOWN         WES19AWN           63         300   \n",
       "102   2020-01-01  3_FROM DOWNTOWN         WES20AWN           63         300   \n",
       "103   2020-01-01  3_FROM DOWNTOWN         WES21AWN           63         300   \n",
       "104   2020-01-01  3_FROM DOWNTOWN         WES23AWN           63         300   \n",
       "105   2020-01-01  3_FROM DOWNTOWN         WES24AWN           63         300   \n",
       "106   2020-01-01  3_FROM DOWNTOWN         WES25AWN           63         300   \n",
       "107   2020-01-01  3_FROM DOWNTOWN         WESNATWN           63         300   \n",
       "108   2020-01-01  3_FROM DOWNTOWN         WES27AWN           63         300   \n",
       "109   2020-01-01  3_FROM DOWNTOWN         WES29AWN           63         300   \n",
       "110   2020-01-01  3_FROM DOWNTOWN         WES30AWN           63         300   \n",
       "111   2020-01-01  3_FROM DOWNTOWN         WES31AWN           63         300   \n",
       "112   2020-01-01  3_FROM DOWNTOWN         WESACKWN           63         300   \n",
       "113   2020-01-01  3_FROM DOWNTOWN         WES440WN           63         300   \n",
       "114   2020-01-01  3_FROM DOWNTOWN         WESELMWF           63         300   \n",
       "115   2020-01-01  3_FROM DOWNTOWN         WESBOWWN           63         300   \n",
       "116   2020-01-01  3_FROM DOWNTOWN         WESCRAWN           63         300   \n",
       "117   2020-01-01  3_FROM DOWNTOWN         WESWILWM           63         300   \n",
       "118   2020-01-01  3_FROM DOWNTOWN         WESMOCWN           63         300   \n",
       "119   2020-01-01  3_FROM DOWNTOWN         WESLAUWN           63         300   \n",
       "\n",
       "           arrival_time  year  month  day  hour  is_holiday  dayofweek  \\\n",
       "100 2020-01-01 15:46:14  2020      1    1  15.0        True          4   \n",
       "101 2020-01-01 15:46:26  2020      1    1  15.0        True          4   \n",
       "102 2020-01-01 15:46:58  2020      1    1  15.0        True          4   \n",
       "103 2020-01-01 15:47:12  2020      1    1  15.0        True          4   \n",
       "104 2020-01-01 15:48:24  2020      1    1  15.0        True          4   \n",
       "105 2020-01-01 15:48:28  2020      1    1  15.0        True          4   \n",
       "106 2020-01-01 15:48:50  2020      1    1  15.0        True          4   \n",
       "107 2020-01-01 15:49:18  2020      1    1  15.0        True          4   \n",
       "108 2020-01-01 15:49:30  2020      1    1  15.0        True          4   \n",
       "109 2020-01-01 15:49:42  2020      1    1  15.0        True          4   \n",
       "110 2020-01-01 15:50:08  2020      1    1  15.0        True          4   \n",
       "111 2020-01-01 15:51:53  2020      1    1  15.0        True          4   \n",
       "112 2020-01-01 15:52:04  2020      1    1  15.0        True          4   \n",
       "113 2020-01-01 15:52:26  2020      1    1  15.0        True          4   \n",
       "114 2020-01-01 15:52:56  2020      1    1  15.0        True          4   \n",
       "115 2020-01-01 15:53:40  2020      1    1  15.0        True          4   \n",
       "116 2020-01-01 15:53:58  2020      1    1  15.0        True          4   \n",
       "117 2020-01-01 15:54:36  2020      1    1  15.0        True          4   \n",
       "118 2020-01-01 15:54:42  2020      1    1  15.0        True          4   \n",
       "119 2020-01-01 15:54:50  2020      1    1  15.0        True          4   \n",
       "\n",
       "     stop_sequence  darksky_temperature  darksky_humidity  \\\n",
       "100             11               52.555             0.358   \n",
       "101             12               52.555             0.358   \n",
       "102             13               52.555             0.358   \n",
       "103             14               52.555             0.358   \n",
       "104             15               52.555             0.358   \n",
       "105             16               52.555             0.358   \n",
       "106             17               52.555             0.358   \n",
       "107             18               52.555             0.358   \n",
       "108             19               52.555             0.358   \n",
       "109             20               52.555             0.358   \n",
       "110             21               52.555             0.358   \n",
       "111             22               52.555             0.358   \n",
       "112             23               52.555             0.358   \n",
       "113             24               52.555             0.358   \n",
       "114             25               52.555             0.358   \n",
       "115             26               52.555             0.358   \n",
       "116             27               52.555             0.358   \n",
       "117             28               52.555             0.358   \n",
       "118             29               52.555             0.358   \n",
       "119             30               52.555             0.358   \n",
       "\n",
       "     darksky_precipitation_probability  traffic_speed  sched_hdwy  load  \n",
       "100                                0.0      17.727612      2400.0   6.0  \n",
       "101                                0.0      17.727612      2400.0   5.0  \n",
       "102                                0.0      17.727612      2400.0   5.0  \n",
       "103                                0.0      17.727612      2400.0   6.0  \n",
       "104                                0.0      17.727612      2400.0   6.0  \n",
       "105                                0.0      17.727612      2400.0   6.0  \n",
       "106                                0.0      17.727612      2400.0   4.0  \n",
       "107                                0.0      17.727612      2400.0   4.0  \n",
       "108                                0.0      17.727612      2400.0   4.0  \n",
       "109                                0.0      17.727612      2400.0   4.0  \n",
       "110                                0.0      17.727612      2400.0   4.0  \n",
       "111                                0.0      17.727612      2400.0   6.0  \n",
       "112                                0.0      17.727612      2400.0   6.0  \n",
       "113                                0.0      17.727612      2400.0   6.0  \n",
       "114                                0.0      17.727612      2400.0   6.0  \n",
       "115                                0.0      17.727612      2400.0   6.0  \n",
       "116                                0.0      17.727612      2400.0   6.0  \n",
       "117                                0.0      17.727612      2400.0   6.0  \n",
       "118                                0.0      17.727612      2400.0   6.0  \n",
       "119                                0.0      17.727612      2400.0   6.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(overall_df.shape)\n",
    "overall_df[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['arrival_time', 'block_abbr']\n",
    "drop_cols = [col for col in drop_cols if col in overall_df.columns]\n",
    "overall_df = overall_df.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4130605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: [(0.0, 6.0), (7.0, 12.0), (13.0, 55.0), (56.0, 75.0), (76.0, 100.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 2., 3., 4.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking bins of loads for possible classification problem\n",
    "loads = overall_df[overall_df.load <= config.TARGET_MAX]['load']\n",
    "percentiles = []\n",
    "for cbin in config.CLASS_BINS:\n",
    "    percentile = np.percentile(loads.values, cbin)\n",
    "    percentiles.append(percentile)\n",
    "\n",
    "# percentiles = [(percentiles[0], percentiles[1]), (percentiles[1] + 1, percentiles[2]), (percentiles[2] + 1, percentiles[3])]\n",
    "percentiles = [(percentiles[0], percentiles[1]), (percentiles[1] + 1, percentiles[2]), (percentiles[2] + 1, 55.0), (56.0, 75.0), (76.0, 100.0)]\n",
    "print(f\"Percentiles: {percentiles}\")\n",
    "overall_df[config.TARGET_COLUMN_CLASSIFICATION] = overall_df['load'].apply(lambda x: data_utils.get_class(x, percentiles))\n",
    "overall_df = overall_df[overall_df[config.TARGET_COLUMN_CLASSIFICATION].notna()]\n",
    "overall_df.y_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5088996\n",
       "2.0    4517975\n",
       "1.0    4293333\n",
       "3.0      64488\n",
       "4.0      15133\n",
       "Name: y_class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df.y_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'past': 10,\n",
       " 'future': 1,\n",
       " 'offset': 0,\n",
       " 'learning_rate': 0.0001,\n",
       " 'batch_size': 256,\n",
       " 'epochs': 200,\n",
       " 'patience': 10}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hyperparameters\n",
    "past = 10 # Past stops observed\n",
    "future = 1 # Future stops predicted\n",
    "offset = 0\n",
    "\n",
    "learning_rate = 1e-4\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "\n",
    "feature_label = config.TARGET_COLUMN_CLASSIFICATION\n",
    "patience = 10\n",
    "\n",
    "hyperparams_dict = {'past': past,\n",
    "                    'future': future,\n",
    "                    'offset': offset,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'batch_size': batch_size,\n",
    "                    'epochs': epochs,\n",
    "                    'patience': patience}\n",
    "hyperparams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['darksky_temperature', 'darksky_humidity', 'darksky_precipitation_probability', 'sched_hdwy', 'traffic_speed']\n",
      "Categorical columns: ['month', 'hour', 'day', 'stop_sequence', 'stop_id_original', 'year', 'time_window', 'y_class']\n",
      "One Hot Encode columns: ['dayofweek', 'route_id_dir', 'is_holiday']\n"
     ]
    }
   ],
   "source": [
    "# target = config.TARGET_COLUMN_CLASSIFICATION\n",
    "target = 'y_class'\n",
    "\n",
    "num_columns = ['darksky_temperature', 'darksky_humidity', 'darksky_precipitation_probability', 'sched_hdwy', 'traffic_speed']\n",
    "cat_columns = ['month', 'hour', 'day', 'stop_sequence', 'stop_id_original', 'year', 'time_window', target]\n",
    "ohe_columns = ['dayofweek', 'route_id_dir', 'is_holiday']\n",
    "\n",
    "columns = num_columns + cat_columns + ohe_columns\n",
    "print(f\"Numerical columns: {num_columns}\")\n",
    "print(f\"Categorical columns: {cat_columns}\")\n",
    "print(f\"One Hot Encode columns: {ohe_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transit_date</th>\n",
       "      <th>route_id_dir</th>\n",
       "      <th>stop_id_original</th>\n",
       "      <th>time_window</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>darksky_temperature</th>\n",
       "      <th>darksky_humidity</th>\n",
       "      <th>darksky_precipitation_probability</th>\n",
       "      <th>traffic_speed</th>\n",
       "      <th>sched_hdwy</th>\n",
       "      <th>load</th>\n",
       "      <th>y_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3_FROM DOWNTOWN</td>\n",
       "      <td>MCC5_5</td>\n",
       "      <td>40</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40.15</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.639604</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transit_date     route_id_dir stop_id_original  time_window  year  month  \\\n",
       "0   2020-01-01  3_FROM DOWNTOWN           MCC5_5           40  2020      1   \n",
       "\n",
       "   day  hour  is_holiday  dayofweek  stop_sequence  darksky_temperature  \\\n",
       "0    1  10.0        True          4              1                40.15   \n",
       "\n",
       "   darksky_humidity  darksky_precipitation_probability  traffic_speed  \\\n",
       "0             0.616                                0.0      18.639604   \n",
       "\n",
       "   sched_hdwy  load  y_class  \n",
       "0      4800.0   7.0      1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10., 11., 12., 15., 16., 17.,  6.,  7.,  8., 18.,  5.,  9., 13.,\n",
       "        14., 19., 20.,  0., 21., 22., 23.,  4.,  1.]),\n",
       " array([ 1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,  2, 47, 48, 49, 50, 51,\n",
       "        52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "        69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83],\n",
       "       dtype=int32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_df.hour.unique(), overall_df.stop_sequence.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = ('2020-01-01', '2021-06-30')\n",
    "val_dates =   ('2021-06-30', '2021-10-31')\n",
    "test_dates =  ('2021-10-31', '2022-04-06')\n",
    "\n",
    "ohe_encoder, label_encoder, num_scaler, train_df, val_df, test_df = linklevel_utils.prepare_linklevel(overall_df, \n",
    "                                                                                                 train_dates=train_dates, \n",
    "                                                                                                 val_dates=val_dates, \n",
    "                                                                                                 test_dates=test_dates,\n",
    "                                                                                                 cat_columns=cat_columns,\n",
    "                                                                                                 num_columns=num_columns,\n",
    "                                                                                                 ohe_columns=ohe_columns,\n",
    "                                                                                                 feature_label='y_class',\n",
    "                                                                                                 time_feature_used='transit_date',\n",
    "                                                                                                 scaler='minmax')\n",
    "\n",
    "drop_cols = ['transit_date', 'load', 'arrival_time']\n",
    "drop_cols = [col for col in drop_cols if col in train_df.columns]\n",
    "train_df = train_df.drop(drop_cols, axis=1)\n",
    "val_df = val_df.drop(drop_cols, axis=1)\n",
    "test_df = test_df.drop(drop_cols, axis=1)\n",
    "\n",
    "arrange_cols = [target] + [col for col in train_df.columns if col != target]\n",
    "train_df = train_df[arrange_cols]\n",
    "val_df = val_df[arrange_cols]\n",
    "test_df = test_df[arrange_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['y_class'] = train_df.y_class.astype('int')\n",
    "val_df['y_class']   = val_df.y_class.astype('int')\n",
    "test_df['y_class']  = test_df.y_class.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving encoders, scalers and column arrangement\n",
    "fp = os.path.join('models', 'same_day', 'LL_OHE_encoder.joblib')\n",
    "joblib.dump(ohe_encoder, fp)\n",
    "fp = os.path.join('models', 'same_day', 'LL_Label_encoders.joblib')\n",
    "joblib.dump(label_encoder, fp)\n",
    "fp = os.path.join('models', 'same_day', 'LL_Num_scaler.joblib')\n",
    "joblib.dump(num_scaler, fp)\n",
    "fp = os.path.join('models', 'same_day', 'LL_X_columns.joblib')\n",
    "joblib.dump(train_df.columns, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can add shuffle in the future\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def timeseries_dataset_from_dataset(df, feature_slice, label_slice, input_sequence_length, output_sequence_length, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(df.values)\n",
    "    ds = dataset.window(input_sequence_length + output_sequence_length, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda x: x).batch(input_sequence_length + output_sequence_length)\n",
    "     \n",
    "    def split_feature_label(x):\n",
    "        return x[:input_sequence_length:, feature_slice], x[input_sequence_length:,label_slice]\n",
    "     \n",
    "    ds = ds.map(split_feature_label)\n",
    "     \n",
    "    return ds.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = train_df.columns.tolist().index(target)\n",
    "print(label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_slice = slice(label_index, label_index + 1, None) # which column the label/labels are\n",
    "feature_slice = slice(None, None, None) # Which feature columns are included, by default includes all (even label)\n",
    "input_sequence_length = past # number of past information to look at\n",
    "output_sequence_length = future # number of time steps to predict\n",
    "\n",
    "dataset_train = timeseries_dataset_from_dataset(train_df, \n",
    "                                                feature_slice=feature_slice,\n",
    "                                                label_slice=label_slice,\n",
    "                                                input_sequence_length=input_sequence_length, \n",
    "                                                output_sequence_length=output_sequence_length, \n",
    "                                                batch_size=batch_size)\n",
    "\n",
    "dataset_val = timeseries_dataset_from_dataset(val_df, \n",
    "                                              feature_slice=feature_slice,\n",
    "                                              label_slice=label_slice,\n",
    "                                              input_sequence_length=input_sequence_length, \n",
    "                                              output_sequence_length=output_sequence_length, \n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "dataset_test = timeseries_dataset_from_dataset(test_df,\n",
    "                                               feature_slice=feature_slice,\n",
    "                                               label_slice=label_slice,\n",
    "                                               input_sequence_length=input_sequence_length, \n",
    "                                               output_sequence_length=output_sequence_length, \n",
    "                                               batch_size=batch_size)\n",
    "for batch in dataset_train.take(1):\n",
    "    (x, y) = batch\n",
    "    display(pd.DataFrame(x[100], columns=train_df.columns))\n",
    "    print(x[100].shape)\n",
    "    display(pd.DataFrame(y[100], columns=['y_class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_df.y_class.unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "# model.compile(\n",
    "#     loss=\"mean_absolute_error\",\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "#     metrics=tf.keras.metrics.MeanSquaredError(),\n",
    "# )\n",
    "\n",
    "input_shape = (None, None, len(train_df.columns))\n",
    "model.build(input_shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'models/same_day/model/CLA_cp-epoch{epoch:02d}-loss{val_loss:.2f}.ckpt'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True), model_checkpoint_callback]\n",
    "\n",
    "history = model.fit(dataset_train, validation_data=dataset_val, epochs=epochs, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "* Load model and encoders,scalers,converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TIMEWINDOW = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "latest = tf.train.latest_checkpoint('models/same_day/model')\n",
    "columns = joblib.load('models/same_day/LL_X_columns.joblib')\n",
    "label_encoders = joblib.load('models/same_day/LL_Label_encoders.joblib')\n",
    "ohe_encoder = joblib.load('models/same_day/LL_OHE_encoder.joblib')\n",
    "num_scaler = joblib.load('models/same_day/LL_Num_scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apc_data_for_date(filter_date):\n",
    "    print(\"Running this...\")\n",
    "    filepath = os.path.join('data', 'processed', 'apc_weather_gtfs.parquet')\n",
    "    apcdata = spark.read.load(filepath)\n",
    "    apcdata.createOrReplaceTempView(\"apc\")\n",
    "\n",
    "    plot_date = filter_date.strftime('%Y-%m-%d')\n",
    "    get_columns = ['trip_id', 'transit_date', 'arrival_time', 'vehicle_id', 'ons',\n",
    "                   'block_abbr', 'stop_sequence', 'stop_name', 'stop_id_original',\n",
    "                   'load', \n",
    "                   'darksky_temperature', \n",
    "                   'darksky_humidity', \n",
    "                   'darksky_precipitation_probability', \n",
    "                   'route_direction_name', 'route_id', 'gtfs_direction_id',\n",
    "                   'dayofweek',  'year', 'month', 'hour',\n",
    "                   'sched_hdwy']\n",
    "    get_str = \", \".join([c for c in get_columns])\n",
    "    query = f\"\"\"\n",
    "    SELECT {get_str}\n",
    "    FROM apc\n",
    "    WHERE (transit_date == '{plot_date}')\n",
    "    ORDER BY arrival_time\n",
    "    \"\"\"\n",
    "    apcdata = spark.sql(query)\n",
    "    apcdata = apcdata.withColumn(\"route_id_dir\", F.concat_ws(\"_\", apcdata.route_id, apcdata.route_direction_name))\n",
    "    apcdata = apcdata.withColumn(\"day\", F.dayofmonth(apcdata.arrival_time))\n",
    "    apcdata = apcdata.drop(\"route_direction_name\")\n",
    "    apcdata = apcdata.withColumn(\"load\", F.when(apcdata.load < 0, 0).otherwise(apcdata.load))\n",
    "    return apcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_data(input_df, ohe_encoder, label_encoders, num_scaler, columns, keep_columns=[], target='y_class'):\n",
    "    num_columns = ['darksky_temperature', 'darksky_humidity', 'darksky_precipitation_probability', 'sched_hdwy', 'traffic_speed']\n",
    "    cat_columns = ['month', 'hour', 'day', 'stop_sequence', 'stop_id_original', 'year', 'time_window']\n",
    "    ohe_columns = ['dayofweek', 'route_id_dir', 'is_holiday']\n",
    "\n",
    "    # OHE\n",
    "    input_df[ohe_encoder.get_feature_names_out()] = ohe_encoder.transform(input_df[ohe_columns]).toarray()\n",
    "    # input_df = input_df.drop(columns=ohe_columns)\n",
    "\n",
    "    # Label encoder\n",
    "    for cat in cat_columns:\n",
    "        encoder = label_encoders[cat]\n",
    "        input_df[cat] = encoder.transform(input_df[cat])\n",
    "    \n",
    "    # Num scaler\n",
    "    input_df[num_columns] = num_scaler.transform(input_df[num_columns])\n",
    "    input_df['y_class']  = input_df.y_class.astype('int')\n",
    "\n",
    "    if keep_columns:\n",
    "        columns = keep_columns + columns\n",
    "    # Rearrange columns\n",
    "    input_df = input_df[columns]\n",
    "    \n",
    "    return input_df\n",
    "\n",
    "def assign_data_to_bins(df, TARGET='load'):\n",
    "    bins = pd.IntervalIndex.from_tuples([(-1, 6.0), (7.0, 12.0), (13.0, 55.0), (56.0, 75.0), (76.0, 100.0)])\n",
    "    mycut = pd.cut(df[TARGET].tolist(), bins=bins)\n",
    "    df['y_class'] = mycut.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running this...\n"
     ]
    }
   ],
   "source": [
    "date_to_predict = dt.date(2021, 10, 18)\n",
    "apcdata = get_apc_data_for_date(date_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = apcdata.toPandas()\n",
    "df = df[df.arrival_time.notna()]\n",
    "df = df[df.sched_hdwy.notna()]\n",
    "df = df[df.darksky_temperature.notna()]\n",
    "\n",
    "df['day'] = df[\"arrival_time\"].dt.day\n",
    "df = df.sort_values(by=['block_abbr', 'arrival_time']).reset_index(drop=True)\n",
    "\n",
    "# Adding extra features\n",
    "# Holidays\n",
    "fp = os.path.join('data', 'others', 'US Holiday Dates (2004-2021).csv')\n",
    "holidays_df = pd.read_csv(fp)\n",
    "holidays_df['Date'] = pd.to_datetime(holidays_df['Date'])\n",
    "holidays_df['is_holiday'] = True\n",
    "df = df.merge(holidays_df[['Date', 'is_holiday']], left_on='transit_date', right_on='Date', how='left')\n",
    "df['is_holiday'] = df['is_holiday'].fillna(False)\n",
    "df = df.drop(columns=['Date'])\n",
    "\n",
    "# Traffic\n",
    "# Causes 3M data points to be lost\n",
    "fp = os.path.join('data', 'traffic', 'triplevel_speed.pickle')\n",
    "speed_df = pd.read_pickle(fp)\n",
    "speed_df = speed_df.rename({'route_id_direction':'route_id_dir'}, axis=1)\n",
    "speed_df = speed_df[['transit_date', 'trip_id', 'route_id_dir', 'traffic_speed']]\n",
    "df = df.merge(speed_df, how='left', \n",
    "                left_on=['transit_date', 'trip_id', 'route_id_dir'], \n",
    "                right_on=['transit_date', 'trip_id', 'route_id_dir'])\n",
    "# df = df[~df['traffic_speed'].isna()]\n",
    "df['traffic_speed'].bfill(inplace=True)\n",
    "\n",
    "df['minute'] = df['arrival_time'].dt.minute\n",
    "df['minuteByWindow'] = df['minute'] // TIMEWINDOW\n",
    "df['temp'] = df['minuteByWindow'] + (df['hour'] * 60 / TIMEWINDOW)\n",
    "df['time_window'] = np.floor(df['temp']).astype('int')\n",
    "df = df.drop(columns=['minute', 'minuteByWindow', 'temp'])\n",
    "\n",
    "# HACK\n",
    "df = df[df['hour'] != 3]\n",
    "df = df[df['stop_sequence'] != 0]\n",
    "\n",
    "df = df.sort_values(by=['block_abbr', 'arrival_time']).reset_index(drop=True)\n",
    "\n",
    "df = assign_data_to_bins(df, TARGET='load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month\n",
      "hour\n",
      "day\n",
      "stop_sequence\n",
      "stop_id_original\n",
      "year\n",
      "time_window\n"
     ]
    }
   ],
   "source": [
    "input_df = prepare_input_data(df, ohe_encoder, label_encoders, num_scaler, columns, target='y_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simple_lstm_predictions(input_df, model, past, future):\n",
    "    past_df = input_df[0:past]\n",
    "    future_df = input_df[past:]\n",
    "    predictions = []\n",
    "    for f in range(future):\n",
    "        pred = model.predict(past_df.to_numpy().reshape(1, *past_df.shape))\n",
    "        y_pred = np.argmax(pred)\n",
    "        predictions.append(y_pred)\n",
    "        \n",
    "        # Add information from future\n",
    "        last_row = future_df.iloc[[0]]\n",
    "        last_row['y_class'] = y_pred\n",
    "        past_df = pd.concat([past_df[1:], last_row])\n",
    "        \n",
    "        # Move future to remove used row\n",
    "        future_df = future_df[1:]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = input_df[0:20]\n",
    "model = linklevel_utils.setup_simple_lstm_generator(input_df.shape[1], 5)\n",
    "model.load_weights(latest)\n",
    "y_pred = generate_simple_lstm_predictions(tdf, model, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>268878_2022-04-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              trip_id y_true y_pred\n",
       "0   268878_2022-04-04    1.0   None\n",
       "1   268878_2022-04-04    1.0      2\n",
       "2   268878_2022-04-04    1.0      2\n",
       "3   268878_2022-04-04    1.0      2\n",
       "4   268878_2022-04-04    1.0      2\n",
       "5   268878_2022-04-04    1.0      2\n",
       "6   268878_2022-04-04    1.0      2\n",
       "7   268878_2022-04-04    0.0      2\n",
       "8   268878_2022-04-04    0.0      2\n",
       "9   268878_2022-04-04    0.0      2\n",
       "10  268878_2022-04-04    0.0      2\n",
       "11  268878_2022-04-04    0.0      2\n",
       "12  268878_2022-04-04    0.0      1\n",
       "13  268878_2022-04-04    0.0      1\n",
       "14  268878_2022-04-04    0.0      1\n",
       "15  268878_2022-04-04    0.0      1\n",
       "16  268878_2022-04-04    0.0      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# fp = os.path.join('../models/same_day/evaluation/SIMPLE_LSTM_multi_stop_5P_xF_results.pkl')\n",
    "fp = os.path.join('../models/same_day/evaluation/baseline_multi_stop_10P_xF_results.pkl')\n",
    "df = pd.read_pickle(fp)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88d12193eb5d2fbe298f9bb9e457ac6a535b56551d0f537fc14a1636657a2895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
