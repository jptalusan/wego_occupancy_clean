{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/jptalusan/mta_stationing_problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from src.config import *\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from src import data_utils, triplevel_utils\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.data_utils' from '/media/seconddrive/mta_stationing_problem/src/data_utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(data_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/08 04:14:14 WARN Utils: Your hostname, scope-vanderbilt resolves to a loopback address: 127.0.1.1; using 10.2.218.69 instead (on interface enp8s0)\n",
      "22/09/08 04:14:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/08 04:14:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/08 04:14:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config('spark.executor.cores', '8').config('spark.executor.memory', '40g')\\\n",
    "        .config(\"spark.sql.session.timeZone\", \"UTC\").config('spark.driver.memory', '20g').master(\"local[26]\")\\\n",
    "        .appName(\"wego-daily\").config('spark.driver.extraJavaOptions', '-Duser.timezone=UTC').config('spark.executor.extraJavaOptions', '-Duser.timezone=UTC')\\\n",
    "        .config(\"spark.sql.datetime.java8API.enabled\", \"true\").config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the APC data from a prepared file\n",
    "processed_triplevel = os.path.join('data', 'processed', 'triplevel_df.parquet')\n",
    "if not os.path.exists(processed_triplevel):\n",
    "    filepath = os.path.join(os.getcwd(), \"data\", \"processed\", \"apc_weather_gtfs.parquet\")\n",
    "    apcdata = spark.read.load(filepath)\n",
    "    apcdata.createOrReplaceTempView(\"apc\")\n",
    "\n",
    "    # filter subset\n",
    "    query = f\"\"\"\n",
    "                SELECT *\n",
    "                FROM apc\n",
    "            \"\"\"\n",
    "    apcdata=spark.sql(query)\n",
    "    apcdata = data_utils.remove_nulls_from_apc(apcdata)\n",
    "    apcdata.createOrReplaceTempView('apcdata')\n",
    "    apcdata_per_trip = data_utils.get_apc_per_trip_sparkview(spark)\n",
    "    df = apcdata_per_trip.toPandas()\n",
    "    \n",
    "    # Adding extra features\n",
    "    # Holidays\n",
    "    fp = os.path.join('data', 'others', 'US Holiday Dates (2004-2021).csv')\n",
    "    holidays_df = pd.read_csv(fp)\n",
    "    holidays_df['Date'] = pd.to_datetime(holidays_df['Date'])\n",
    "    holidays_df['is_holiday'] = True\n",
    "    df = df.merge(holidays_df[['Date', 'is_holiday']], left_on='transit_date', right_on='Date', how='left')\n",
    "    df['is_holiday'] = df['is_holiday'].fillna(False)\n",
    "    df = df.drop(columns=['Date'])\n",
    "    \n",
    "    # School breaks\n",
    "    fp = os.path.join('data', 'others', 'School Breaks (2019-2022).pkl')\n",
    "    school_break_df = pd.read_pickle(fp)\n",
    "    school_break_df['is_school_break'] = True\n",
    "    df = df.merge(school_break_df[['Date', 'is_school_break']], left_on='transit_date', right_on='Date', how='left')\n",
    "    df['is_school_break'] = df['is_school_break'].fillna(False)\n",
    "    df = df.drop(columns=['Date'])\n",
    "\n",
    "    # Traffic\n",
    "    fp = os.path.join('data', 'traffic', 'triplevel_speed.pickle')\n",
    "    speed_df = pd.read_pickle(fp)\n",
    "    speed_df = speed_df[['transit_date', 'trip_id', 'route_id_direction', 'traffic_speed']]\n",
    "    df = df.merge(speed_df, how='left', \n",
    "                  left_on =['transit_date', 'trip_id', 'route_id_direction'], \n",
    "                  right_on=['transit_date', 'trip_id', 'route_id_direction'])\n",
    "    df = df[~df['traffic_speed'].isna()]\n",
    "    df.to_parquet(processed_triplevel, engine='auto', compression='gzip')\n",
    "else:\n",
    "    df = pd.read_parquet(processed_triplevel, engine='auto')\n",
    "    df = df.dropna()\n",
    "    # Removing time_window in case a different one will be used\n",
    "df = df.drop(['time_window', 'load'], axis=1)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis (used features)\n",
    "* Datetime: `year`, `month`, `dayofweek`, `hour`, `day`\n",
    "* GTFS: `scheduled_headway`, `route_direction_name`, `route_id`, `block_abbr`\n",
    "* Weather: `temperature`, `humidity`, `precipitation_intensity`\n",
    "* APC data on a stop level is grouped into trips and data is gathered by using the first instance (route_id, route_direction_name) or the average of the numerical values (scheduled headay, weather data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430404, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>transit_date</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_direction_name</th>\n",
       "      <th>block_abbr</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipitation_intensity</th>\n",
       "      <th>scheduled_headway</th>\n",
       "      <th>actual_headways</th>\n",
       "      <th>y_reg100</th>\n",
       "      <th>y_reg095</th>\n",
       "      <th>route_id_direction</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_school_break</th>\n",
       "      <th>traffic_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193715</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-01 17:24:14</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>FROM DOWNTOWN</td>\n",
       "      <td>1400</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>49.390999</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3654.976744</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14_FROM DOWNTOWN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>19.483279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_id transit_date        arrival_time  year  month  route_id  \\\n",
       "0  193715   2020-01-01 2020-01-01 17:24:14  2020      1        14   \n",
       "\n",
       "  route_direction_name  block_abbr  dayofweek  hour  temperature  humidity  \\\n",
       "0        FROM DOWNTOWN        1400          4    17    49.390999     0.467   \n",
       "\n",
       "   precipitation_intensity  scheduled_headway  actual_headways  y_reg100  \\\n",
       "0                      0.0             3600.0      3654.976744       9.0   \n",
       "\n",
       "   y_reg095 route_id_direction  is_holiday  is_school_break  traffic_speed  \n",
       "0       9.0   14_FROM DOWNTOWN        True             True      19.483279  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>transit_date</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_direction_name</th>\n",
       "      <th>block_abbr</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipitation_intensity</th>\n",
       "      <th>scheduled_headway</th>\n",
       "      <th>actual_headways</th>\n",
       "      <th>y_reg100</th>\n",
       "      <th>y_reg095</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_school_break</th>\n",
       "      <th>traffic_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>route_id_direction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94_FROM NASHVILLE</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38_TO DOWNTOWN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95_FROM NASHVILLE</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35_TO DOWNTOWN</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72_GRASSMERE</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22_FROM DOWNTOWN</th>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "      <td>17937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56_FROM DOWNTOWN</th>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "      <td>19273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55_FROM DOWNTOWN</th>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "      <td>19357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52_TO DOWNTOWN</th>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "      <td>19457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52_FROM DOWNTOWN</th>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "      <td>24188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    trip_id  transit_date  arrival_time   year  month  \\\n",
       "route_id_direction                                                      \n",
       "94_FROM NASHVILLE         1             1             1      1      1   \n",
       "38_TO DOWNTOWN            1             1             1      1      1   \n",
       "95_FROM NASHVILLE         2             2             2      2      2   \n",
       "35_TO DOWNTOWN            4             4             4      4      4   \n",
       "72_GRASSMERE              8             8             8      8      8   \n",
       "...                     ...           ...           ...    ...    ...   \n",
       "22_FROM DOWNTOWN      17937         17937         17937  17937  17937   \n",
       "56_FROM DOWNTOWN      19273         19273         19273  19273  19273   \n",
       "55_FROM DOWNTOWN      19357         19357         19357  19357  19357   \n",
       "52_TO DOWNTOWN        19457         19457         19457  19457  19457   \n",
       "52_FROM DOWNTOWN      24188         24188         24188  24188  24188   \n",
       "\n",
       "                    route_id  route_direction_name  block_abbr  dayofweek  \\\n",
       "route_id_direction                                                          \n",
       "94_FROM NASHVILLE          1                     1           1          1   \n",
       "38_TO DOWNTOWN             1                     1           1          1   \n",
       "95_FROM NASHVILLE          2                     2           2          2   \n",
       "35_TO DOWNTOWN             4                     4           4          4   \n",
       "72_GRASSMERE               8                     8           8          8   \n",
       "...                      ...                   ...         ...        ...   \n",
       "22_FROM DOWNTOWN       17937                 17937       17937      17937   \n",
       "56_FROM DOWNTOWN       19273                 19273       19273      19273   \n",
       "55_FROM DOWNTOWN       19357                 19357       19357      19357   \n",
       "52_TO DOWNTOWN         19457                 19457       19457      19457   \n",
       "52_FROM DOWNTOWN       24188                 24188       24188      24188   \n",
       "\n",
       "                     hour  temperature  humidity  precipitation_intensity  \\\n",
       "route_id_direction                                                          \n",
       "94_FROM NASHVILLE       1            1         1                        1   \n",
       "38_TO DOWNTOWN          1            1         1                        1   \n",
       "95_FROM NASHVILLE       2            2         2                        2   \n",
       "35_TO DOWNTOWN          4            4         4                        4   \n",
       "72_GRASSMERE            8            8         8                        8   \n",
       "...                   ...          ...       ...                      ...   \n",
       "22_FROM DOWNTOWN    17937        17937     17937                    17937   \n",
       "56_FROM DOWNTOWN    19273        19273     19273                    19273   \n",
       "55_FROM DOWNTOWN    19357        19357     19357                    19357   \n",
       "52_TO DOWNTOWN      19457        19457     19457                    19457   \n",
       "52_FROM DOWNTOWN    24188        24188     24188                    24188   \n",
       "\n",
       "                    scheduled_headway  actual_headways  y_reg100  y_reg095  \\\n",
       "route_id_direction                                                           \n",
       "94_FROM NASHVILLE                   1                1         1         1   \n",
       "38_TO DOWNTOWN                      1                1         1         1   \n",
       "95_FROM NASHVILLE                   2                2         2         2   \n",
       "35_TO DOWNTOWN                      4                4         4         4   \n",
       "72_GRASSMERE                        8                8         8         8   \n",
       "...                               ...              ...       ...       ...   \n",
       "22_FROM DOWNTOWN                17937            17937     17937     17937   \n",
       "56_FROM DOWNTOWN                19273            19273     19273     19273   \n",
       "55_FROM DOWNTOWN                19357            19357     19357     19357   \n",
       "52_TO DOWNTOWN                  19457            19457     19457     19457   \n",
       "52_FROM DOWNTOWN                24188            24188     24188     24188   \n",
       "\n",
       "                    is_holiday  is_school_break  traffic_speed  \n",
       "route_id_direction                                              \n",
       "94_FROM NASHVILLE            1                1              1  \n",
       "38_TO DOWNTOWN               1                1              1  \n",
       "95_FROM NASHVILLE            2                2              2  \n",
       "35_TO DOWNTOWN               4                4              4  \n",
       "72_GRASSMERE                 8                8              8  \n",
       "...                        ...              ...            ...  \n",
       "22_FROM DOWNTOWN         17937            17937          17937  \n",
       "56_FROM DOWNTOWN         19273            19273          19273  \n",
       "55_FROM DOWNTOWN         19357            19357          19357  \n",
       "52_TO DOWNTOWN           19457            19457          19457  \n",
       "52_FROM DOWNTOWN         24188            24188          24188  \n",
       "\n",
       "[70 rows x 20 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('route_id_direction').count().sort_values('trip_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "Generated features, $y_t = f(x_{t-1})$, are always generated using past information.\n",
    "* `time_window`: Assigning the arrival times into time windows (30 minutes by default).\n",
    "* `window_of_day`: Just a larger time window (could probably remove)\n",
    "* `actual_headways`: On a stop level, actual headways are given using the arrival times of the bus to the bus stop. On a trip level, this was averaged over the multiple bus stops across a single trip.\n",
    "* `congestion_surrogate`: Generated by a model trained on the scheduled and actual headways. (tentatively included, surrogate model is not yet that accurate)\n",
    "* `route_id_direction`: Combined route_id and route_direction into one feature and then one hot encoded.\n",
    "* Other categorical values are converted to ordinal integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 100\n",
    "WINDOW = 30\n",
    "PAST_TRIPS = 5\n",
    "TARGET = 'y_reg100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['route_id_direction', 'is_holiday', 'dayofweek', 'is_school_break', 'time_window']\n",
    "ord_features = ['year', 'month', 'hour', 'day']\n",
    "num_features = ['temperature', 'humidity', 'precipitation_intensity', 'avg_sched_headway', 'traffic_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the interest of time\n",
    "tdf = deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = triplevel_utils.generate_new_features(df, time_window=WINDOW, past_trips=PAST_TRIPS, target=TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by time windows and get the maximum of the aggregate load/class/sched\n",
    "# Get mean of temperature (mostly going to be equal)\n",
    "tdf = tdf.groupby(['transit_date', 'route_id_direction', 'time_window']).agg({\"year\":\"first\", \n",
    "                                                                              \"month\":\"first\",\n",
    "                                                                              \"day\": \"first\",\n",
    "                                                                              \"dayofweek\":\"first\", \n",
    "                                                                              \"hour\":\"first\",\n",
    "                                                                              \"is_holiday\": \"first\",\n",
    "                                                                              \"is_school_break\": \"first\",\n",
    "                                                                              \"temperature\":\"mean\", \n",
    "                                                                              \"humidity\":\"mean\",\n",
    "                                                                              \"traffic_speed\":\"mean\",\n",
    "                                                                              \"precipitation_intensity\": \"mean\",\n",
    "                                                                              \"scheduled_headway\": \"max\",\n",
    "                                                                              TARGET: \"max\"})\n",
    "tdf = tdf.reset_index(level=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ohe_encoder is for the following column order:\", cat_features)\n",
    "rf_df, ix_map, ohe_encoder, percentiles = triplevel_utils.prepare_df_for_training(tdf, cat_features, ord_features, target=TARGET)\n",
    "percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['route_id', 'route_direction_name', 'block_abbr', 'y_reg100', 'y_reg095', 'transit_date', 'is_holiday', 'route_id_direction', 'actual_headways', 'trip_id', 'arrival_time']\n",
    "drop_cols = [col for col in drop_cols if col in rf_df.columns]\n",
    "rf_df = rf_df.drop(drop_cols, axis=1)\n",
    "\n",
    "display(rf_df['y_class'].value_counts())\n",
    "\n",
    "y = rf_df.pop('y_class')\n",
    "X = rf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "X.head(5).style.set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.unique())\n",
    "pd.DataFrame(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('models', 'any_day', 'TL_OHE_encoders.joblib')\n",
    "joblib.dump(ohe_encoder, fp)\n",
    "fp = os.path.join('models', 'any_day', 'TL_IX_map.joblib')\n",
    "joblib.dump(ix_map, fp)\n",
    "fp = os.path.join('models', 'any_day', 'TL_X_columns.joblib')\n",
    "joblib.dump(X.columns, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search results\n",
    "fp = os.path.join('models', 'any_day', 'XGBOOST_RANDSEARCHCV_any_day_with_schoolbreak012.joblib')\n",
    "search_results = joblib.load(fp)\n",
    "print(search_results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For bins 012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on entire dataset\n",
    "\n",
    "n_estimators  = search_results.best_params_['n_estimators']\n",
    "max_depth     = search_results.best_params_['max_depth']\n",
    "learning_rate = search_results.best_params_['learning_rate']\n",
    "gamma         = search_results.best_params_['gamma']\n",
    "objective     = 'multi:softmax'\n",
    "\n",
    "model012 = xgb.XGBClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                             learning_rate=learning_rate, use_label_encoder=False, gamma=gamma, num_class=3,\n",
    "                             objective=objective, eval_metric='mlogloss')\n",
    "# model012 = xgb.XGBClassifier(use_label_encoder=False, num_class=3,\n",
    "#                              objective=objective, eval_metric='mlogloss')\n",
    "\n",
    "model012.fit(X, y, verbose=1)\n",
    "\n",
    "fp = os.path.join('models', 'any_day', 'XGB_012.joblib')\n",
    "joblib.dump(model012, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For bins 234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_df, ix_map, ohe_encoder, percentiles = triplevel_utils.prepare_df_for_training(tdf, cat_features, ord_features, target=TARGET)\n",
    "\n",
    "# Train 2 separate models for bins 0, 1, 2 and 2, 3, 4\n",
    "# Adjusting y_class to incorporate Dan's request\n",
    "# Use Transit's 3 bins as a base. For the highest capacity bin, carve out everything from 55 to 75 as a 4th bin, and 75+ as a 5th bin.\n",
    "\n",
    "rf_df, percentiles = triplevel_utils.adjust_bins(rf_df, TARGET=TARGET, percentiles=percentiles)\n",
    "display(rf_df['y_class'].value_counts())\n",
    "print(percentiles)\n",
    "drop_cols = ['route_id', 'route_direction_name', 'block_abbr', 'y_reg100', 'y_reg095', 'transit_date', 'is_holiday', 'route_id_direction', 'is_school_break']\n",
    "drop_cols = [col for col in drop_cols if col in rf_df.columns]\n",
    "rf_df = rf_df.drop(drop_cols, axis=1)\n",
    "rf_df = rf_df[rf_df['y_class'] >= 2]\n",
    "display(rf_df['y_class'].value_counts())\n",
    "\n",
    "y = rf_df.pop('y_class')\n",
    "y = y - 2\n",
    "X = rf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search results\n",
    "fp = os.path.join('models', 'any_day', 'XGBOOST_RANDSEARCHCV_any_day_with_schoolbreak234.joblib')\n",
    "search_results = joblib.load(fp)\n",
    "print(search_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on entire dataset\n",
    "n_estimators  = search_results.best_params_['n_estimators']\n",
    "max_depth     = search_results.best_params_['max_depth']\n",
    "learning_rate = search_results.best_params_['learning_rate']\n",
    "gamma         = search_results.best_params_['gamma']\n",
    "objective     = 'multi:softmax'\n",
    "\n",
    "model234 = xgb.XGBClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                            learning_rate=learning_rate, use_label_encoder=False, gamma=gamma, num_class=3,\n",
    "                            objective=objective, eval_metric='mlogloss')\n",
    "# model234 = xgb.XGBClassifier(use_label_encoder=False, num_class=3,\n",
    "#                              objective=objective, eval_metric='mlogloss')\n",
    "\n",
    "model234.fit(X, y, verbose=1)\n",
    "\n",
    "fp = os.path.join('models', 'any_day', 'XGB_234.joblib')\n",
    "joblib.dump(model234, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('models', 'any_day', 'XGB_012_simple.joblib')\n",
    "model012 = joblib.load(fp)\n",
    "\n",
    "fp = os.path.join('models', 'any_day', 'XGB_234_simple.joblib')\n",
    "model234 = joblib.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model234.predict(X)\n",
    "X.iloc[np.where(y_pred == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model234.predict(X.loc[y[y == 2].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual prediction process\n",
    "> Can move to separate notebook\n",
    "0. Mirror streamlit variables\n",
    "1. Select date to predict\n",
    "2. Get past data from range that share day of week values\n",
    "3. Get average of certain values\n",
    "4. Adjust data for new prediction date\n",
    "5. Setup, predict and output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model012    = joblib.load('models/any_day/XGB_012_simple.joblib')\n",
    "model234    = joblib.load('models/any_day/XGB_234_simple.joblib')\n",
    "columns     = joblib.load('models/any_day/TL_X_columns.joblib')\n",
    "ix_map      = joblib.load('models/any_day/TL_IX_map.joblib')\n",
    "ohe_encoder = joblib.load('models/any_day/TL_OHE_encoders.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from src import any_day_prediction_utils as prediction\n",
    "date_to_predict = dt.date(2022, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_df = prediction.get_past_data(spark, date_to_predict)\n",
    "input_df = prediction.setup_input_data(date_to_predict, past_df)\n",
    "display(input_df)\n",
    "input_df = prediction.prepare_any_day_for_prediction(input_df, columns, ix_map, ohe_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = input_df.reset_index(drop=True)\n",
    "input_df = input_df[columns]\n",
    "\n",
    "## Predict first stage 0-1-2\n",
    "predictions = model012.predict(input_df)\n",
    "\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "print(unique, counts)\n",
    "\n",
    "input_df['y_pred'] = predictions\n",
    "## Isolate predictions with bin 2 for 2-3-4\n",
    "high_bin_df = input_df[input_df['y_pred'] == 2]\n",
    "display(high_bin_df)\n",
    "high_bin_df = high_bin_df.drop(['y_pred'], axis=1)\n",
    "high_bin_index = high_bin_df.index\n",
    "high_bin_df = high_bin_df[columns]\n",
    "\n",
    "predictions = model234.predict(high_bin_df)\n",
    "\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "print(unique, counts)\n",
    "\n",
    "predictions = predictions + 2\n",
    "input_df.loc[high_bin_index, 'y_pred'] = predictions\n",
    "ohe_features = ['route_id_direction', 'is_holiday', 'dayofweek', 'is_school_break']\n",
    "input_df[ohe_features] = ohe_encoder.inverse_transform(input_df.filter(regex='route_id_direction_|is_holiday_|dayofweek_|is_school_'))\n",
    "\n",
    "results = prediction.generate_results(input_df, TIMEWINDOW=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(results, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model012.predict(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model012.predict(X[(X['month_ix'] == 9) & (X['day_ix'] == 10)][columns])\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model012.predict(X[columns])\n",
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "os.chdir(\"/media/seconddrive/mta_stationing_problem\")\n",
    "fp = os.path.join('models/any_day/XGBOOST_RANDSEARCHCV_any_day.pkl')\n",
    "best = joblib.load(fp)\n",
    "best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88d12193eb5d2fbe298f9bb9e457ac6a535b56551d0f537fc14a1636657a2895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
